{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_metodo(modelo, X_train, y_train, X_test, y_test, mostrar=False):\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Realizar predicciones en los datos de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calcula métricas\n",
    "    matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    score_auc = auc(fpr, tpr)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Mostrar la Curva ROC\n",
    "    if mostrar:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f\"AUC = {score_auc:.2f}\")\n",
    "        plt.plot([0, 1], [0, 1], 'r--')\n",
    "        plt.xlabel('FPR')\n",
    "        plt.ylabel('TPR')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # Devolver las métricas en un diccionario\n",
    "    return { 'Matriz de Confusión': matriz_confusion, 'AUC': score_auc,\n",
    "        'Accuracy': accuracy, 'MSE': mse\n",
    "    }\n",
    "\n",
    "def cross_validation(modelo, k, X, y):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    resultados = {\n",
    "        'Accuracy': [],\n",
    "        'AUC': [],\n",
    "        'MSE': []\n",
    "    }\n",
    "\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        resultado = evalua_metodo(modelo, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        # Agregar resultados de cada fold a la lista correspondiente\n",
    "        resultados['AUC'].append(resultado['AUC'])\n",
    "        resultados['Accuracy'].append(resultado['Accuracy'])\n",
    "        resultados['MSE'].append(resultado['MSE'])\n",
    "\n",
    "    # Calcular el promedio de cada métrica\n",
    "    promedios = {key: np.mean(val) for key, val in resultados.items()}\n",
    "    \n",
    "    return promedios\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: {'Matriz de Confusión': array([[ 56,   7],\n",
      "       [  2, 106]]), 'AUC': 0.9907407407407407, 'Accuracy': 0.9473684210526315, 'MSE': 0.05263157894736842}\n",
      "KNN CV: {'Accuracy': 0.9472442167365317, 'AUC': 0.9877519236729324, 'MSE': 0.0527557832634684}\n",
      "KNN: {'Matriz de Confusión': array([[ 59,   4],\n",
      "       [  1, 107]]), 'AUC': 0.9805261610817166, 'Accuracy': 0.9707602339181286, 'MSE': 0.029239766081871343}\n",
      "KNN CV: {'Accuracy': 0.9507529886663562, 'AUC': 0.9864858906508879, 'MSE': 0.04924701133364384}\n",
      "Logistic Regression: {'Matriz de Confusión': array([[ 60,   3],\n",
      "       [  1, 107]]), 'AUC': 0.9979423868312757, 'Accuracy': 0.9766081871345029, 'MSE': 0.023391812865497075}\n",
      "Logistic Regression CV: {'Accuracy': 0.9753920198726906, 'AUC': 0.9954850276788912, 'MSE': 0.02460798012730942}\n"
     ]
    }
   ],
   "source": [
    "# Cargar el conjunto de datos de cáncer de mama\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instanciar los modelos\n",
    "modelo_lda = LDA()\n",
    "modelo_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "modelo_logistic = LogisticRegression()\n",
    "\n",
    "# Evaluar LDA\n",
    "print(\"KNN:\", evalua_metodo(modelo_lda, X_train, y_train, X_test, y_test))\n",
    "print(\"KNN CV:\", cross_validation(modelo_lda, 5, X, y))\n",
    "\n",
    "# Evaluar KNN\n",
    "print(\"KNN:\", evalua_metodo(modelo_knn, X_train, y_train, X_test, y_test))\n",
    "print(\"KNN CV:\", cross_validation(modelo_knn, 5, X, y))\n",
    "\n",
    "# Evaluar Logistic Regression\n",
    "print(\"Logistic Regression:\", evalua_metodo(modelo_logistic, X_train, y_train, X_test, y_test))\n",
    "print(\"Logistic Regression CV:\", cross_validation(modelo_logistic, 5, X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Suponiendo que X_scaled y y están ya definidos y listos para usar\u001b[39;00m\n\u001b[1;32m     39\u001b[0m modelo_base \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m mejor_config, menor_error \u001b[38;5;241m=\u001b[39m \u001b[43mevalua_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejor configuración:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mejor_config)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMenor error MSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, menor_error)\n",
      "Cell \u001b[0;32mIn[109], line 16\u001b[0m, in \u001b[0;36mevalua_config\u001b[0;34m(modelo_base, configs, k, X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m res_cv \u001b[38;5;241m=\u001b[39m cross_validation(modelo, k, X, y)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Calcular el error promedio (MSE) de la validación cruzada\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m mse_promedio \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMSE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res_cv])\n\u001b[1;32m     17\u001b[0m resultados\u001b[38;5;241m.\u001b[39mappend((config, mse_promedio))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Actualizar la mejor configuración si el MSE actual es el menor\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "def evalua_config(modelo_base, configs, k, X, y):\n",
    "    mejor_config = None\n",
    "    menor_error = 100000000\n",
    "    resultados = []\n",
    "\n",
    "    # Iterar sobre cada configuración de hiperparámetros\n",
    "    for config in configs:\n",
    "        # Crear una instancia del modelo con la configuración actual\n",
    "        modelo = clone(modelo_base)\n",
    "        modelo.set_params(**config)\n",
    "        \n",
    "        # Realizar validación cruzada\n",
    "        res_cv = cross_validation(modelo, k, X, y)\n",
    "        \n",
    "        # Calcular el error promedio (MSE) de la validación cruzada\n",
    "        mse_promedio = np.mean([r['MSE'] for r in res_cv])\n",
    "        resultados.append((config, mse_promedio))\n",
    "        \n",
    "        # Actualizar la mejor configuración si el MSE actual es el menor\n",
    "        if mse_promedio < menor_error:\n",
    "            menor_error = mse_promedio\n",
    "            mejor_config = config\n",
    "\n",
    "    print(\"Resultados por configuración:\")\n",
    "    for conf, error in resultados:\n",
    "        print(f\"Configuración: {conf}, MSE Promedio: {error:.4f}\")\n",
    "    \n",
    "    return mejor_config, menor_error\n",
    "\n",
    "# Ejemplo de uso con regresión logística para buscar el λ óptimo en regularización\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Configuraciones de prueba para el hiperparámetro C (inverso de λ)\n",
    "c = np.logspace(-5,5,11)\n",
    "configs = [{'penalty': 'l2', 'C': i} for i in c]\n",
    "\n",
    "# Suponiendo que X_scaled y y están ya definidos y listos para usar\n",
    "modelo_base = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "mejor_config, menor_error = evalua_config(modelo_base, configs, 5, X_scaled, y)\n",
    "print(\"Mejor configuración:\", mejor_config)\n",
    "print(\"Menor error MSE:\", menor_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_multiples_metodos(X, y):\n",
    "    # Dividir los datos en entrenamiento, validación y prueba\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "    # Configuraciones para la regresión logística\n",
    "    configs = [\n",
    "        {'penalty': 'l2', 'C': 0.01},\n",
    "        {'penalty': 'l2', 'C': 0.1},\n",
    "        {'penalty': 'l2', 'C': 1},\n",
    "        {'penalty': 'l2', 'C': 10},\n",
    "        {'penalty': 'l2', 'C': 100}\n",
    "    ]\n",
    "    \n",
    "    # Optimizar hiperparámetros para la regresión logística\n",
    "    modelo_logistic = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    mejor_config, _ = evalua_config(modelo_logistic, configs, 5, X_train, y_train)\n",
    "    modelo_logistic.set_params(**mejor_config)\n",
    "    \n",
    "    # Evaluar la regresión logística optimizada en el conjunto de prueba\n",
    "    resultados_logistic = evalua_metodo(modelo_logistic, X_train_val, y_train_val, X_test, y_test)\n",
    "    \n",
    "    # Evaluar LDA\n",
    "    modelo_lda = LDA()\n",
    "    resultados_lda = evalua_metodo(modelo_lda, X_train_val, y_train_val, X_test, y_test)\n",
    "    \n",
    "    # Evaluar KNN con k=3\n",
    "    modelo_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    resultados_knn = evalua_metodo(modelo_knn, X_train_val, y_train_val, X_test, y_test)\n",
    "    \n",
    "    # Preparar la tabla de resultados\n",
    "    resultados = pd.DataFrame({\n",
    "        'Modelo': ['Regresión Logística', 'LDA', 'KNN k=3'],\n",
    "        'Configuración': [str(mejor_config), 'N/A', 'k=3'],\n",
    "        'Accuracy': [resultados_logistic['Accuracy'], resultados_lda['Accuracy'], resultados_knn['Accuracy']],\n",
    "        'AUC': [resultados_logistic['AUC'], resultados_lda['AUC'], resultados_knn['AUC']],\n",
    "        'MSE': [resultados_logistic['MSE'], resultados_lda['MSE'], resultados_knn['MSE']]\n",
    "    })\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Ejemplo de uso\n",
    "# Suponiendo que X_scaled y y están ya definidos y listos para usar\n",
    "resultados_modelos = evalua_multiples_metodos(X_scaled, y)\n",
    "print(resultados_modelos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
